#!/bin/sh

# Script: run_onchange_after_install_ai_models.sh.tmpl
# Purpose: Install AI models based on destination configuration
# Requirements: Arch Linux, ollama

{{ if eq .osId "linux-arch" }}
    {{- $destinationConfig := index .destinations .destination }}
    
    echo "Installing AI models for {{ .destination }} destination..."
    
    # Check if AI models should be installed for this destination
    {{- if $destinationConfig.ai_models }}
    
    # Check if ollama is installed and running
    if ! command -v ollama >/dev/null 2>&1; then
        echo "Ollama not found, skipping AI model installation"
        exit 0
    fi
    
    # Check if ollama service is running
    if ! systemctl --user is-active ollama >/dev/null 2>&1; then
        echo "Starting ollama service..."
        systemctl --user start ollama
        sleep 5
    fi
    
    echo "Installing AI models..."
    
    # Install each model
    {{- range .ai.models }}
    echo "Installing model: {{ . }}"
    ollama pull {{ . }}
    {{- end }}
    
    echo "âœ“ AI models installed successfully"
    
    {{- else }}
    echo "AI models disabled for {{ .destination }} destination, skipping..."
    {{- end }}
    
{{ else }}
    echo "ERROR: Unsupported OS: {{ .osId }}"
    echo "This script requires: linux-arch"
    exit 1
{{ end }}
