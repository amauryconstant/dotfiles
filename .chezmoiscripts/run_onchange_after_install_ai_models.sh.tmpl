#!/bin/sh

# Script: run_onchange_after_install_ai_models.sh.tmpl
# Purpose: Install AI models based on destination configuration
# Requirements: Arch Linux, ollama

{{ includeTemplate "arch_linux_check" . }}
{{- $destinationConfig := index .destinations .destination }}

{{ includeTemplate "log_start" (printf "Installing AI models for %s destination..." .destination) }}

# Check if AI models should be installed for this destination
{{- if $destinationConfig.ai_models }}

# Check if ollama is installed and running
if ! command -v ollama >/dev/null 2>&1; then
    {{ includeTemplate "log_skip" "Ollama not found, skipping AI model installation" }}
    exit 0
fi

# Check if ollama service is running
if ! systemctl --user is-active ollama >/dev/null 2>&1; then
    {{ includeTemplate "log_step" "Starting ollama service..." }}
    systemctl --user start ollama
    sleep 5
fi

{{ includeTemplate "log_step" "Installing AI models..." }}

# Install each model
{{- range .ai.models }}
{{ includeTemplate "log_progress" (printf "Installing model: %s" .) }}
ollama pull {{ . }}
{{- end }}

{{ includeTemplate "log_success" "AI models installed successfully" }}

{{- else }}
{{ includeTemplate "log_skip" (printf "AI models disabled for %s destination" .destination) }}
{{- end }}
